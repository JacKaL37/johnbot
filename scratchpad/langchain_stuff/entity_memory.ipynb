{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c9933a",
   "metadata": {},
   "source": [
    "# Conversation Knowledge Graph\n",
    "\n",
    "This type of memory uses a knowledge graph to recreate memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a133eb",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/jon/github_repos/jonmatthis/jonbot/scratchpad/langchain_stuff\n",
      "\u001B[31mERROR: file:///Users/jon/github_repos/jonmatthis/jonbot/scratchpad/langchain_stuff does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001B[0m\u001B[31m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3 -m pip install --upgrade pip\u001B[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# !/usr/local/bin/python3.9 -m pip install --upgrade pip\n",
    "# %pip install langchain --quiet\n",
    "# %pip install openai --quiet\n",
    "# %pip install python-dotenv --quiet\n",
    "# %pip install networkx --quiet\n",
    "# %pip install tiktoken --quiet\n",
    "# %pip install motor --quiet\n",
    "# %pip install pymongo --quiet\n",
    "# %pip install python-dotenv\n",
    "%pip install -e . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c798006-ca04-4de3-83eb-cf167fb2bd01",
   "metadata": {},
   "source": [
    "## Using memory with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f71f40ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T23:49:41.071826Z",
     "start_time": "2023-10-02T23:49:40.943973Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jonbot'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m/Users/jon/github_repos/jonmatthis/jonbot/scratchpad/langchain_stuff/entity_memory.ipynb Cell 4\u001B[0m line \u001B[0;36m7\n\u001B[1;32m      <a href='vscode-notebook-cell:/Users/jon/github_repos/jonmatthis/jonbot/scratchpad/langchain_stuff/entity_memory.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001B[0m \u001B[39mfrom\u001B[39;00m \u001B[39mdotenv\u001B[39;00m \u001B[39mimport\u001B[39;00m load_dotenv\n\u001B[1;32m      <a href='vscode-notebook-cell:/Users/jon/github_repos/jonmatthis/jonbot/scratchpad/langchain_stuff/entity_memory.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001B[0m \u001B[39mimport\u001B[39;00m \u001B[39mjson\u001B[39;00m\n\u001B[0;32m----> <a href='vscode-notebook-cell:/Users/jon/github_repos/jonmatthis/jonbot/scratchpad/langchain_stuff/entity_memory.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001B[0m \u001B[39mfrom\u001B[39;00m \u001B[39mjonbot\u001B[39;00m\u001B[39m.\u001B[39;00m\u001B[39mbackend\u001B[39;00m\u001B[39m.\u001B[39;00m\u001B[39mdata_layer\u001B[39;00m\u001B[39m.\u001B[39;00m\u001B[39mdatabase\u001B[39;00m\u001B[39m.\u001B[39;00m\u001B[39mget_or_create_mongo_database_manager\u001B[39;00m \u001B[39mimport\u001B[39;00m get_mongo_database_manager\n\u001B[1;32m      <a href='vscode-notebook-cell:/Users/jon/github_repos/jonmatthis/jonbot/scratchpad/langchain_stuff/entity_memory.ipynb#X55sZmlsZQ%3D%3D?line=8'>9</a>\u001B[0m load_dotenv()\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'jonbot'"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain.llms import OpenAI\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "from jonbot.backend.data_layer.database.get_or_create_mongo_database_manager import get_mongo_database_manager\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b37dd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T23:49:35.421647Z",
     "start_time": "2023-10-02T23:49:35.402673Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mongo_database_manager = get_mongo_database_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17ef96",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111265ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T23:46:40.842959Z",
     "start_time": "2023-10-02T23:46:40.688212Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "chat_json_path = Path(\"/Users/jon/Dropbox/Northeastern/Courses/neural_control_of_real_world_human_movement/2023-09-Fall/classbot_data/backup/2023-10-02_classbot_database.chats.json\")\n",
    "\n",
    "with chat_json_path.open('r') as file:\n",
    "    chats_og = json.load(file)\n",
    "\n",
    "chats_= {}\n",
    "\n",
    "for chat in chats:\n",
    "    parent_message_id = chat[\"parent_id\"]\n",
    "    if parent_message_id not in chats_by_student:\n",
    "        chats_by_student[student_id] = []\n",
    "    chats_by_student[student_id].append(chat)\n",
    "\n",
    "print_string = [f\"{student_id}: {len(chats)} chats\" for student_id, chats in chats_by_student.items()]\n",
    "print(\"\\n\".join(print_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Chunk big text into little chunkos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:33:02.459361Z",
     "start_time": "2023-09-28T01:33:02.445268Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_file_name = \"sara_shams_and_the_astrolabe_20230917.txt\"\n",
    "big_text = open(text_file_name, 'r').read()\n",
    "text_split_by_newline = big_text.split(\"\\n\")\n",
    "\n",
    "chunk_lengths_og = [len(chunk) for chunk in text_split_by_newline]\n",
    "\n",
    "#remove empty chunks\n",
    "text_split_by_newline = [chunk for chunk in text_split_by_newline if len(chunk) > 1]\n",
    "\n",
    "chunk_lengths = [len(chunk) for chunk in text_split_by_newline]\n",
    "\n",
    "print(f\"Big text is {len(big_text)} characters long, and split into {len(text_split_by_newline)} lines. The longest line is {max(chunk_lengths)} characters long\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:33:02.503747Z",
     "start_time": "2023-09-28T01:33:02.457112Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine texts split by newline into chunks of 1000 characters\n",
    "chunk_size = 2000\n",
    "text_split_by_newline = [chunk for chunk in text_split_by_newline if len(chunk) > 1]\n",
    "\n",
    "text_chunks = []\n",
    "current_chunk = \"\"\n",
    "for text in text_split_by_newline:\n",
    "    if len(current_chunk) + len(text) < chunk_size:\n",
    "        current_chunk += text + \"\\n\"\n",
    "    else:\n",
    "        text_chunks.append(current_chunk)\n",
    "        current_chunk = text + \"\\n\"\n",
    "\n",
    "mean_chunk_length = sum([len(chunk) for chunk in text_chunks])/len(text_chunks)\n",
    "print(f\"Combined lines into {len(text_chunks)} chunks of roughly {chunk_size} characters each (mean chunk length is {mean_chunk_length})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:33:02.826482Z",
     "start_time": "2023-09-28T01:33:02.465948Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "tokens_in_string = num_tokens_from_string(big_text, \"cl100k_base\")\n",
    "\n",
    "# token prices for GPT-3.5-turbo 4k\n",
    "# Model\tInput\tOutput\n",
    "# 4K context\t$0.0015 / 1K tokens\t$0.002 / 1K tokens\n",
    "\n",
    "cost_per_token_gpt35  = 0.0015/1000\n",
    "cost_per_token_gpt4 = 0.03/1000\n",
    "\n",
    "total_cost_35 = tokens_in_string * cost_per_token_gpt35\n",
    "total_cost_4 = tokens_in_string * cost_per_token_gpt4\n",
    "\n",
    "print(f\"Text is {tokens_in_string} tokens long, and costs ${total_cost_35} to input into GPT-3.5-turbo, and ${total_cost_4} to input into GPT-4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  Stuff the story into the memory, one chunk at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:33:10.760995Z",
     "start_time": "2023-09-28T01:33:02.828928Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0,\n",
    "                 model_name=\"gpt-3.5-turbo\",\n",
    "                 callbacks=[StdOutCallbackHandler()],\n",
    "                 streaming = True)\n",
    "\n",
    "entity_memory = ConversationEntityMemory(llm=llm)\n",
    "conversation_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=entity_memory\n",
    ")\n",
    "\n",
    "human_input = \"I am going to tell you the story of Sara Shams and the Astrolabe written by Paul Matthis. It is a long story, so I will tell it to you in chunks. When I tell you each chunk, you will ask me what happens next. I will then tell you what happens next. We will continue this until I tell you that the story is over. Then you will tell me what happened in the story.\"\n",
    "print(conversation_chain.run(input=human_input ))\n",
    "\n",
    "print(\"KG memory is set up!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:33:10.773018Z",
     "start_time": "2023-09-28T01:33:10.754864Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# conversation_with_kg.predict(input=\"Who is Paul Matthis?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:33:10.773491Z",
     "start_time": "2023-09-28T01:33:10.759493Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# conversation_with_kg.predict(input=\"What are we doing here? What's the plan?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:52:49.448554Z",
     "start_time": "2023-09-28T01:33:10.773227Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "use_chunks = -1\n",
    "\n",
    "for chunk_number, chunk in enumerate(text_chunks[:use_chunks]):\n",
    "    print(f\"Inputting chunk {chunk_number} of {len(text_chunks[:use_chunks])}\")\n",
    "    print(conversation_chain.run(input=chunk))\n",
    "    print(\"----------------\\n\"\n",
    "          \"----------------\")\n",
    "\n",
    "human_input = \"That's all for now, I'll tell you more later.\"\n",
    "conversation_chain.run(input=human_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:53:43.853268Z",
     "start_time": "2023-09-28T01:53:36.898224Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(conversation_chain.run(input =\"what is this story about?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:54:26.071586Z",
     "start_time": "2023-09-28T01:54:25.607475Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entity_memory.load_memory_variables({\"input\": \"who is Sara?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:54:44.522533Z",
     "start_time": "2023-09-28T01:54:36.349095Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conversation_chain.predict(input=\"Who are the characters in this story?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:56:08.394075Z",
     "start_time": "2023-09-28T01:56:08.383156Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint( entity_memory.entity_store.store, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T02:01:53.916860Z",
     "start_time": "2023-09-28T02:01:53.620449Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entity_memory.load_memory_variables({\"input\": \"who is the author of this book?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
